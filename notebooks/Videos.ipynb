{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# 当引用模块和运行的脚本不在同一个目录下，需在脚本开头添加如下代码：\n",
    "sys.path.append('/home/mt/learn/SSD-Tensorflow-master/')\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as mpcm\n",
    "import matplotlib.image as mpimg\n",
    "from notebooks import visualization\n",
    "from nets import ssd_vgg_300, ssd_common, np_methods\n",
    "from preprocessing import ssd_vgg_preprocessing\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "# TensorFlow session\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "config = tf.ConfigProto(log_device_placement=False, gpu_options=gpu_options)\n",
    "isess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/mt/learn/SSD-Tensorflow-master/checkpoints/ssd_300_vgg.ckpt\n"
     ]
    }
   ],
   "source": [
    "l_VOC_CLASS = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "               'bus', 'car', 'cat', 'chair', 'cow',\n",
    "               'diningTable', 'dog', 'horse', 'motorbike', 'person',\n",
    "               'pottedPlant', 'sheep', 'sofa', 'train', 'TV']\n",
    "\n",
    "# 定义数据格式，设置占位符\n",
    "net_shape = (300, 300)\n",
    "# 预处理，以Tensorflow backend, 将输入图片大小改成 300x300，作为下一步输入\n",
    "img_input = tf.placeholder(tf.uint8, shape=(None, None, 3))\n",
    "# 输入图像的通道排列形式，'NHWC'表示 [batch_size,height,width,channel]\n",
    "data_format = 'NHWC'\n",
    "\n",
    "# 数据预处理，将img_input输入的图像resize为300大小，labels_pre,bboxes_pre,bbox_img待解析\n",
    "image_pre, labels_pre, bboxes_pre, bbox_img = ssd_vgg_preprocessing.preprocess_for_eval(\n",
    "    img_input, None, None, net_shape, data_format,\n",
    "    resize=ssd_vgg_preprocessing.Resize.WARP_RESIZE)\n",
    "# 拓展为4维变量用于输入\n",
    "image_4d = tf.expand_dims(image_pre, 0)\n",
    "\n",
    "# 定义SSD模型\n",
    "# 是否复用，目前我们没有在训练所以为None\n",
    "reuse = True if 'ssd_net' in locals() else None\n",
    "# 调出基于VGG神经网络的SSD模型对象，注意这是一个自定义类对象\n",
    "ssd_net = ssd_vgg_300.SSDNet()\n",
    "# 得到预测类和预测坐标的Tensor对象，这两个就是神经网络模型的计算流程\n",
    "with slim.arg_scope(ssd_net.arg_scope(data_format=data_format)):\n",
    "    predictions, localisations, _, _ = ssd_net.net(image_4d, is_training=False, reuse=reuse)\n",
    "\n",
    "# 导入官方给出的 SSD 模型参数\n",
    "ckpt_filename = '/home/mt/learn/SSD-Tensorflow-master/checkpoints/ssd_300_vgg.ckpt'\n",
    "# ckpt_filename = '../checkpoints/VGG_VOC0712_SSD_300x300_ft_iter_120000.ckpt'\n",
    "isess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(isess, ckpt_filename)\n",
    "\n",
    "# 在网络模型结构中，提取搜索网格的位置\n",
    "# 根据模型超参数，得到每个特征层（这里用了6个特征层，分别是4，7，8，9，10，11）的anchors_boxes\n",
    "ssd_anchors = ssd_net.anchors(net_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载辅助作图函数\n",
    "def colors_subselect(colors, num_classes=21):\n",
    "    dt = len(colors) // num_classes\n",
    "    sub_colors = []\n",
    "    for i in range(num_classes):\n",
    "        color = colors[i * dt]\n",
    "        if isinstance(color[0], float):\n",
    "            sub_colors.append([int(c * 255) for c in color])\n",
    "        else:\n",
    "            sub_colors.append([c for c in color])\n",
    "    return sub_colors\n",
    "\n",
    "\n",
    "def bboxes_draw_on_img(img, classes, scores, bboxes, colors, thickness=2):\n",
    "    shape = img.shape\n",
    "    for i in range(bboxes.shape[0]):\n",
    "        if classes[i]==15:\n",
    "            bbox = bboxes[i]\n",
    "            color = colors[classes[i]]\n",
    "            # Draw bounding box...\n",
    "            p1 = (int(bbox[0] * shape[0]), int(bbox[1] * shape[1]))\n",
    "            p2 = (int(bbox[2] * shape[0]), int(bbox[3] * shape[1]))\n",
    "            cv2.rectangle(img, p1[::-1], p2[::-1], color, thickness)\n",
    "            # Draw text...\n",
    "            s = '%s/%.3f' % (l_VOC_CLASS[int(classes[i]) - 1], scores[i])\n",
    "            p1 = (p1[0] - 5, p1[1])\n",
    "            # cv2.putText(img, s, p1[::-1], cv2.FONT_HERSHEY_DUPLEX, 1.5, color, 3)\n",
    "\n",
    "\n",
    "colors_plasma = colors_subselect(mpcm.plasma.colors, num_classes=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主流程函数\n",
    "def process_image(img, select_threshold=0.2, nms_threshold=.1, net_shape=(300, 300)):\n",
    "    # select_threshold：box阈值——每个像素的box分类预测数据的得分会与box阈值比较，高于一个box阈值则认为这个box成功框到了一个对象\n",
    "    # nms_threshold：重合度阈值——同一对象的两个框的重合度高于该阈值，则运行下面去重函数\n",
    "\n",
    "    # 执行SSD模型，得到4维输入变量，分类预测，坐标预测，rbbox_img参数为最大检测范围，本文固定为[0,0,1,1]即全图\n",
    "    rimg, rpredictions, rlocalisations, rbbox_img = isess.run([image_4d, predictions, localisations, bbox_img],\n",
    "                                                              feed_dict={img_input: img})\n",
    "\n",
    "    # ssd_bboxes_select函数根据每个特征层的分类预测分数，归一化后的映射坐标，\n",
    "    # ancohor_box的大小，通过设定一个阈值计算得到每个特征层检测到的对象以及其分类和坐标\n",
    "    rclasses, rscores, rbboxes = np_methods.ssd_bboxes_select(rpredictions, rlocalisations, ssd_anchors,\n",
    "                                                              select_threshold=select_threshold,\n",
    "                                                              img_shape=net_shape,\n",
    "                                                              num_classes=21, decode=True)\n",
    "\n",
    "    \"\"\"\n",
    "    这个函数做的事情比较多，这里说的细致一些：\n",
    "    首先是输入，输入的数据为每个特征层（一共6个，见上文）的：\n",
    "                                                分类预测数据（rpredictions），\n",
    "                                                坐标预测数据（rlocalisations），\n",
    "                                                anchors_box数据（ssd_anchors）\n",
    "                                            其中：\n",
    "                                               分类预测数据为当前特征层中每个像素的每个box的分类预测\n",
    "                                               坐标预测数据为当前特征层中每个像素的每个box的坐标预测\n",
    "                                               anchors_box数据为当前特征层中每个像素的每个box的修正数据\n",
    "\n",
    "        函数根据坐标预测数据和anchors_box数据，计算得到每个像素的每个box的中心和长宽，这个中心坐标和长宽会根据一个算法进行些许的修正，\n",
    "    从而得到一个更加准确的box坐标；修正的算法会在后文中详细解释，如果只是为了理解算法流程也可以不必深究这个，因为这个修正算法属于经验算\n",
    "    法，并没有太多逻辑可循。\n",
    "        修正完box和中心后，函数会计算每个像素的每个box的分类预测数据的得分，当这个分数高于一个阈值（这里是0.5）则认为这个box成功\n",
    "    框到了一个对象，然后将这个box的坐标数据，所属分类和分类得分导出，从而得到：\n",
    "        rclasses：所属分类\n",
    "        rscores：分类得分\n",
    "        rbboxes：坐标\n",
    "\n",
    "        最后要注意的是，同一个目标可能会在不同的特征层都被检测到，并且他们的box坐标会有些许不同，这里并没有去掉重复的目标，而是在下文\n",
    "    中专门用了一个函数来去重\n",
    "    \"\"\"\n",
    "\n",
    "    # 检测有没有超出检测边缘\n",
    "    rbboxes = np_methods.bboxes_clip(rbbox_img, rbboxes)\n",
    "    rclasses, rscores, rbboxes = np_methods.bboxes_sort(rclasses, rscores, rbboxes, top_k=400)\n",
    "    # 去重，将重复检测到的目标去掉\n",
    "    rclasses, rscores, rbboxes = np_methods.bboxes_nms(rclasses, rscores, rbboxes, nms_threshold=nms_threshold)\n",
    "    # 将box的坐标重新映射到原图上（上文所有的坐标都进行了归一化，所以要逆操作一次）\n",
    "    rbboxes = np_methods.bboxes_resize(rbbox_img, rbboxes)\n",
    "\n",
    "    bboxes_draw_on_img(img, rclasses, rscores, rbboxes, colors_plasma, thickness=8)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video /home/mt/learn/SSD-Tensorflow-master/Video/output/mmp.mp4\n",
      "[MoviePy] Writing audio in mmpTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490/490 [00:00<00:00, 1321.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] Writing video /home/mt/learn/SSD-Tensorflow-master/Video/output/mmp.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 888/888 [00:27<00:00, 32.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: /home/mt/learn/SSD-Tensorflow-master/Video/output/mmp.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 视频物体定位\n",
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def process_video (input_path, output_path):\n",
    "    video = VideoFileClip(input_path)\n",
    "    result = video.fl_image(process_image)\n",
    "    result.write_videofile(output_path, fps=40)\n",
    "\n",
    "video_name = \"mmp.mp4\"\n",
    "input_path = \"/home/mt/learn/SSD-Tensorflow-master/Video/input/\" + video_name\n",
    "output_path = \"/home/mt/learn/SSD-Tensorflow-master/Video/output/\" + video_name\n",
    "process_video(input_path,output_path )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
